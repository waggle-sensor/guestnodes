#!/usr/bin/python3
# ANL:waggle-license
#  This file is part of the Waggle Platform.  Please see the file
#  LICENSE.waggle.txt for the legal details of the copyright and software
#  license.  For more details on the Waggle project, visit:
#           http://www.wa8.gl
# ANL:waggle-license

import os
import time
import argparse
import cv2
import numpy as np
import sys

import joblib

from waggle.pipeline import ImagePipelineHandler
import waggle.plugin

np.seterr(divide='ignore', invalid='ignore')

def get_default_configuration():
    return {
        'source': 'top',
        'model': '/wagglerw/plugins/cloud-coverage.plugin/plugin_bin/models/swimseg_model_128.pkl',
        'input_scale': 0.00784,
        'input_size': (300, 300),
        'input_mean_subtraction': (127.5, 127.5, 127.5),
        'input_channel_order': 'RGB',
        'detection_interval': 300,  # every 5 mins
        'sampling_interval': -1,  # None, by default
        'detection_confidence': 0.5,  # least detection confidence
    }

ROUTING_KEY_EXPORT = 'exporter'

class CloudEstimator():
    def __init__(self, plugin):
        self.plugin = plugin
        self.config = self._get_config_table()
        self.input_handler = ImagePipelineHandler(
            routing_in=self.config['source'])

    def close(self):
        self.input_handler.close()

    def _get_config_table(self, file_name='/wagglerw/waggle/cloud_coverage_estimator.conf'):
        config = None
        try:
            with open(file_name) as file:
                config = json.load(file)
        except Exception:
            pass

        if config is None:
            config = get_default_configuration()
            try:
                with open(file_name, 'w') as file:
                    file.write(json.dumps(config, sort_keys=True, indent=4))
            except:
                pass
        return config

    def _feature_generator(self, img):
        #Input_Image = img
        #Input_Image = cv2.imread('test_0ca.jpg')
        #Input_Image_RGB = cv2.cvtColor(Input_Image, cv2.COLOR_BGR2RGBA)
        #Input_Image_RGB = Input_Image

        Input_Image_RGB = img

        #Input_Image_HSV = cv2.cvtColor(Input_Image, cv2.COLOR_BGR2HSV)
        Input_Image_HSV = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)

        Image_Array_RGB = np.array(Input_Image_RGB)
        Image_Array_HSV = np.array(Input_Image_HSV)

        Image_Shape = Image_Array_RGB.shape
        Pixels_Count = Image_Shape[0] * Image_Shape[1]

        Input_Image_Red = Image_Array_RGB[:,:,2]
        Input_Image_Blue = Image_Array_RGB[:, :, 0]

        Input_Image_Difference = Input_Image_Red / Input_Image_Blue * 100

        One_D_Image_Red = np.transpose(np.matrix(Image_Array_RGB[:, :, 2].ravel()))
        One_D_Image_Blue = np.transpose(np.matrix(Image_Array_RGB[:, :, 0].ravel()))

        One_D_Image_Red = One_D_Image_Red.astype(np.int16)
        One_D_Image_Blue = One_D_Image_Blue.astype(np.int16)

        One_D_Image_S = np.transpose(np.matrix(Image_Array_HSV[:, :, 1].ravel()))

        One_D_Image_Blue[One_D_Image_Blue == 0] = 1

        ratio = One_D_Image_Red / (One_D_Image_Blue)
        One_D_Image_RATIO = ratio
        ratio = np.reshape(ratio, (Image_Shape[0], Image_Shape[1]))
        img_ratio = np.array(ratio * 255, dtype=np.uint8)

        One_D_Image_DIFF = One_D_Image_Red - One_D_Image_Blue

        One_D_Image_NORMALIZED = ( One_D_Image_Blue - One_D_Image_Red ) / (One_D_Image_Blue + One_D_Image_Red)

        One_D_Image = np.hstack((One_D_Image_S, \
                    One_D_Image_RATIO, \
                    One_D_Image_NORMALIZED, \
                    ))

        return One_D_Image, Image_Shape

    def _soft_thresholding(self, labels):

        min_v = min(labels)
        max_v = max(labels)
        theta = ( labels - min_v ) / ( max_v - min_v )

        return theta

    def _threshold(self, input, target_shape, confidence):

        za = (np.asarray(input) < confidence).sum()
        percentage = (za / (target_shape[0] * target_shape[1])) * 100

        return percentage

    def _coverage_predictor(self, target_feature, model, target_shape):
        # reg_start = time.time()
        Y_pred = model.predict(target_feature)
        # reg_end = time.time()
        # print('inference time {}'.format(reg_end-reg_start))

        ## target_shape[0]: Width, target_shape[1]: Height
        predicted = np.reshape(Y_pred, (target_shape[0], target_shape[1]))
        predicted = np.array(predicted * 255, dtype = np.uint8)
        cv2.imwrite('predicted.jpg', predicted.T)

        return Y_pred

    def _pre_process(self, frame, properties):
        try:
            metadata = properties.headers
            nparr_img = np.fromstring(frame, np.uint8)
            img = cv2.imdecode(nparr_img, cv2.IMREAD_COLOR)
            return True, img
        except Exception as ex:
            return False, str(ex)

    def _process(self, image, benchmark=False):
        try:
            if benchmark is False:
                target_feature, target_shape = self._feature_generator(image)
                predict = self._coverage_predictor(target_feature, model, target_shape)
                soft_thresholded = self._soft_thresholding(predict)
                estimation = self._threshold(soft_thresholded, target_shape, confidence)
                return True, estimation
            else:
                ## feature extraction and soft threshold take most of time
                st = time.time()
                target_feature, target_shape = self._feature_generator(image)
                et = time.time()
                print('feature generator elapsed in %.6f' % (et-st))

                st = time.time()
                predict = self._coverage_predictor(target_feature, model, target_shape)
                et = time.time()
                print('predictor elapsed in %.6f' % (et-st))

                st = time.time()
                soft_thresholded = self._soft_thresholding(predict)
                et = time.time()
                print('soft threshold elapsed in %.6f' % (et-st))

                st = time.time()
                estimation = self._threshold(soft_thresholded, target_shape, confidence)
                et = time.time()
                print('threshold elapsed in %.6f' % (et-st))
                return True, estimation
        except Exception as ex:
            return False, str(ex)

    def run(self):
        model = joblib.load(self.config['model'])

        try:
            confidence = float(self.config['detection_confidence'])
        except Exception:
            print('[Error] Failed to read confidence. Use 0.5 by default...')
            confidence = 0.5

        interval = int(self.config['detection_interval'])

        self.config['last_updated'] = time.time() - self.config['detection_interval']
        self.config['last_sampled'] = time.time() - self.config['sampling_interval']

        if self.config['sampling_interval'] < 1:
            do_sampling = False
        else:
            do_sampling = True

        attempts = 3
        while True:
            for attempt in range(attempts):
                current_time = time.time()
                f, message = self.input_handler.read()
                if f is True:
                    properties, frame = message
                    f, image = self._pre_process(frame, properties)
                    if f is True:
                        f, estimation = self._process(image)
                        if f is True:
                            print('cloud coverage estimation result: {}%'.format(estimation))

                            self.plugin.add_measurement({
                                'sensor_id': 0x3002,
                                'parameter_id': 1,
                                'value': estimation,
                            })
                            self.plugin.publish_measurements()
                            # Sampling the result
                            if do_sampling:
                                result = {
                                    'processing_software': os.path.basename(__file__),
                                    'results': json.dumps(estimation)
                                }
                                properties.headers.update(result)
                                self.input_handler.write(
                                    ROUTING_KEY_EXPORT,
                                    frame,
                                    properties.headers
                                )
                            break
                        else:
                            print('[Error] in processing ', estimation)
                    else:
                        print('[Error] in pre-processing ', image)
                else:
                    print('[Error] in getting message', message)
                print('[Info] Re-attempting in 5 seconds...')
                sleep(5)
            sleep(interval)


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--print', action='store_true')
    args = parser.parse_args()

    if args.print:
        plugin = waggle.plugin.PrintPlugin()
    else:
        plugin = waggle.plugin.Plugin()

    cce = CloudEstimator(plugin)
    cce.run()
