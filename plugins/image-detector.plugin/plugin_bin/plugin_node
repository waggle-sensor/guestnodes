#!/usr/bin/env python3
# ANL:waggle-license
#  This file is part of the Waggle Platform.  Please see the file
#  LICENSE.waggle.txt for the legal details of the copyright and software
#  license.  For more details on the Waggle project, visit:
#           http://www.wa8.gl
# ANL:waggle-license
import argparse
import os
import time
import json
import cv2
import numpy as np
import sys

from waggle.pipeline import Plugin, ImagePipelineHandler
import waggle.plugin

# change working directory to plugin dir
os.chdir(os.path.dirname(sys.argv[0]))

EXCHANGE = 'image_pipeline'
ROUTING_KEY_EXPORT = 'exporter'


parser = argparse.ArgumentParser()
parser.add_argument('--debug', action='store_true')
args = parser.parse_args()

if args.debug:
    plugin = waggle.plugin.PrintPlugin()
else:
    plugin = waggle.plugin.Plugin()


def get_default_configuration():
    return {
        'source': 'bottom',
        'model': 'models/ssd_mobilenet_coco.pb',
        'model_desc': 'models/ssd_mobilenet_coco.pbtxt',
        'classes': 'models/ssd_mobilenet_coco.classes',
        'input_scale': 0.00784,
        'input_size': (300, 300),
        'input_mean_subtraction': (127.5, 127.5, 127.5),
        'input_channel_order': 'RGB',
        'detection_interval': 300,  # every 5 mins
        'sampling_interval': -1,  # None, by default
        'detection_confidence': 0.3,  # least detection confidence
    }


def read_model_file(path, desc):
    _, ext = os.path.splitext(path)
    if 'pb' in ext:
        return cv2.dnn.readNetFromTensorflow(path, desc)
    if 'caffemodel' in ext:
        return cv2.dnn.readNetFromCaffe(path, desc)
    raise ValueError('Model extension {} not recognized.'.format(ext))


class CarPedDetector(Plugin):
    plugin_name = 'image_car_ped_detector'
    plugin_version = '0'

    def __init__(self):
        super().__init__()
        self.config = self._get_config_table()
        self.input_handler = ImagePipelineHandler(
            routing_in=self.config['source'])

    def _get_config_table(self):
        sensor_config_file = '/wagglerw/waggle/image_car_ped_detector.conf'
        sensor_table = None
        try:
            with open(sensor_config_file) as config:
                sensor_table = json.loads(config.read())
        except Exception:
            sensor_table = get_default_configuration()
            os.makedirs('/wagglerw/waggle/')
            with open(sensor_config_file, 'w') as config:
                config.write(json.dumps(sensor_table, sort_keys=True, indent=4))
        return sensor_table

    def _detect(self, img_blob, cvNet, classes, confidence=0.3, img_rows=1, img_cols=1):
        cvNet.setInput(img_blob)
        cvOut = cvNet.forward()

        output = {}
        for detection in cvOut[0, 0, :, :]:
            score = float(detection[2])
            if score > confidence:
                class_index = int(detection[1])
                class_name = classes[class_index]
                if class_name not in output:
                    output[class_name] = {}

                detection_index = len(output[class_name].keys())
                left = int(detection[3] * img_cols)
                top = int(detection[4] * img_rows)
                right = int(detection[5] * img_cols)
                bottom = int(detection[6] * img_rows)

                output[class_name][detection_index] = (
                    left, top, right, bottom
                )
        return output

    def _print(self, detected_objects):
        for detected_object in detected_objects:
            print('%s was found at' % (detected_object,))
            for index, rect in detected_objects[detected_object].items():
                left, top, right, bottom = rect
                x = left + ((right - left) / 2.)
                y = top + ((bottom - top) / 2.)
                print('    x:%5d, y:%5d' % (x, y))
            print('Total: %s %d' % (detected_object, len(
                detected_objects[detected_object].keys())))

    def close(self):
        self.input_handler.close()

    def run(self):
        # Load models
        model_path = self.config['model']
        model_desc = self.config['model_desc']

        print('Loading model {}'.format(model_path))
        cvNet = read_model_file(model_path, model_desc)

        # NOTE: Did not work in Waggle 2.9.0; needs investigation
        # Use OpenCL
        # cvNet.setPreferableBackend(cv2.dnn.DNN_BACKEND_DEFAULT)
        # cvNet.setPreferableTarget(cv2.dnn.DNN_TARGET_OPENCL)

        # Load classes
        classes = {}

        with open(self.config['classes'], 'r') as file:
            for line in file:
                sp = line.strip().split(' ')
                classes[int(sp[0])] = sp[1]

        try:
            confidence = float(self.config['detection_confidence'])
        except Exception:
            confidence = 0.3

        self.config['last_updated'] = time.time(
        ) - self.config['detection_interval']
        self.config['last_sampled'] = time.time(
        ) - self.config['sampling_interval']

        if self.config['sampling_interval'] < 1:
            do_sampling = False
        else:
            do_sampling = True

        while True:
            current_time = time.time()

            if current_time - self.config['last_updated'] > self.config['detection_interval']:
                return_code, message = self.input_handler.read()

                if return_code is True:
                    print('Received frame', flush=True)
                    properties, frame = message
                    metadata = properties.headers
                    nparr_img = np.fromstring(frame, np.uint8)
                    img = cv2.imdecode(nparr_img, cv2.IMREAD_COLOR)

                    rows, cols, _ = img.shape
                    M = cv2.getRotationMatrix2D(
                        (cols / 2, rows / 2), metadata['image_rotate'], 1)
                    img = cv2.warpAffine(img, M, (cols, rows))

                    counter = 0
                    try:
                        img_blob = cv2.dnn.blobFromImage(
                            img,
                            self.config['input_scale'],
                            tuple(self.config['input_size']),
                            tuple(self.config['input_mean_subtraction']),
                            swapRB=True if 'RGB' in self.config['input_channel_order'].upper(
                            ) else False,
                            crop=False
                        )
                        #print("So far %d exceptions" % counter)
                        detected_objects = self._detect(
                            img_blob,
                            cvNet,
                            classes,
                            confidence=confidence,
                            img_rows=img.shape[0],
                            img_cols=img.shape[1]
                        )
                    except Exception:
                        counter = counter + 1
                        print("Exception occurred, caught and continuing")
                        pass

                    cars = detected_objects.get('car', {})
                    people = detected_objects.get('person', {})

                    count_car = len(cars)
                    count_person = len(people)

                    # print('cars={} pedestrians={}'.format(
                    #     count_car, count_person))

                    plugin.add_measurement({
                        'sensor_id': 0x3001,
                        'parameter_id': 1,
                        'value': count_car,
                    })

                    plugin.add_measurement({
                        'sensor_id': 0x3001,
                        'parameter_id': 2,
                        'value': count_person,
                    })

                    plugin.publish_measurements()

                    # Sampling the result
                    if do_sampling:
                        if current_time - self.config['last_sampled'] > self.config['sampling_interval']:
                            result = {
                                'processing_software': os.path.basename(__file__),
                                'results': json.dumps(detected_objects)
                            }
                            properties.headers.update(result)
                            self.input_handler.write(
                                ROUTING_KEY_EXPORT,
                                frame,
                                properties.headers
                            )
                            self.config['last_sampled'] = current_time
                self.config['last_updated'] = current_time
            else:
                wait_time = (self.config['last_updated'] + self.config['detection_interval']) - current_time
                if wait_time > 0.1:
                    time.sleep(wait_time)


if __name__ == '__main__':
    plugin = CarPedDetector.defaultConfig().run()
